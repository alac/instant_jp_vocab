# This is the settings file. To override values here, create a user.toml by coping this.

[ai_settings]
# Oogabooga or Gemini or OpenAI
api = "Oogabooga"

[oobabooga_api]
request_url = 'http://127.0.0.1:5000/v1/completions'
context_length = 4096
# preset_name should be a oobabooga preset; 'none' will use the defaults hardcoded into library/ai_requests.py
preset_name = 'none'

[openai_api]
# supports service that implements a OpenAI-Completions endpoint
request_url = ""
model = ""
api_key = ""

[gemini_pro_api]
# You can get a free api key here: https://ai.google.dev/gemini-api/docs/api-key
api_key = ""
# Pick one of the values from https://ai.google.dev/gemini-api/docs/models/gemini
# Mind the quota limits if you're using a higher quality model
api_model = "gemini-1.5-flash"
system_prompt = """Respond directly with only the requested information.
Do not add any conversational elements, greetings, or explanations.
Use examples provided as a guide and follow the pattern to complete the task."""

[azure_tts]
# Azure has a generous speech synthesis free plan
# Follow the instructions here to setup an account: https://learn.microsoft.com/en-us/azure/ai-services/speech-service/get-started-text-to-speech?tabs=windows%2Cterminal&pivots=programming-language-python#prerequisites
speech_key = ""
speech_region = ""
# Provided JP voices are:
#ja-JP-NanamiNeural
#ja-JP-KeitaNeural
#ja-JP-AoiNeural
#ja-JP-DaichiNeural
#ja-JP-MayuNeural
#ja-JP-NaokiNeural
#ja-JP-ShioriNeural
#ja-JP-MasaruMultilingualNeural
speech_voice = "ja-JP-KeitaNeural"

[define]
define_prompt_filepath = "prompts/define_base_forms.txt"
temperature = 0.7

[translate]
translate_prompt_filepath = "prompts/translate.txt"
temperature = 0.7

[translate_cot]
# Aka 'With Analysis (CoT)'. The idea is to ask questions to direct the translation.
cot_prompt_filepath = "prompts/cot_translation.txt"
cot_examples_filepath = "prompts/examples/cot_translation_original.txt"
save_cot_outputs = false
temperature = 0.7

[define_into_analysis]
# Aka 'Define->Analysis'. The idea is to improve the quality of readings by supplying them from a trusted source.
# enable_jmdict_replacements changes the behavior of Define->Analysis to look up readings in JMDict.
# The first time this is ON, it will extract JMDict which is VERY slow.
enable_jmdict_replacements = false

[translate_best_of_three]
# Aka 'Best of Three'. The idea is ask for three different translations and (optionally) ask the AI to pick the best one.
# enable_validation asks the AI to judge which translation was best. Very sketchy.
enable_validation = false
first_temperature = 0.0
second_temperature = 0.5
third_temperature = 1.0

[q_and_a]
q_and_a_prompt_filepath = "prompts/q_and_a.txt"
temperature = 0.0

[ui]
# You can set the behavior of the translate, analyze and define buttons.
# 'Translate' just AI translates the sentence
# 'Best of Three' does 3 separate AI translations and optionally asks which is the best.
# 'With Analysis (CoT)' asks clarification questions before asking for a translations.
# 'Define->Analysis' is the above with an extra step to try to get more accurate readings.
# 'Post-Hoc Analysis' is 'Translate' then 'With Analysis (CoT)'
# 'Define' asks for a vocabulary list without a translation
# 'Define (without AI)' attempts to generate a vocabulary list without AI at all
translate_button_action = 'Translate'
analyze_button_action = 'With Analysis (CoT)'
define_button_action = 'Define'

[general]
# The number of previous clipboard values to send to the AI as context.
translation_history_length = 15
# An additional 'context' to send with the AI request.
# Use this to describe lines that will be translated.
# For a story, this might be a synopsis or a list of characters.
translation_context = """>STORY_INFO_START
Example story data. The main character is the protagonist.
>STORY_INFO_END
"""
